{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WfrCFmLHxYu"
      },
      "source": [
        "# CS3033/CS6405 - Data Mining - Second Assignment\n",
        "\n",
        "### Submission\n",
        "\n",
        "This assignment is **due on 06/04/22 at 23:59**. You should submit a single .ipnyb file with your python code and analysis electronically via Canvas.\n",
        "Please note that this assignment will account for 25 Marks of your module grade.\n",
        "\n",
        "### Declaration\n",
        "\n",
        "By submitting this assignment. I agree to the following:\n",
        "\n",
        "<font color=\"red\">“I have read and understand the UCC academic policy on plagiarism, and agree to the requirements set out thereby in relation to plagiarism and referencing. I confirm that I have referenced and acknowledged properly all sources used in the preparation of this assignment.\n",
        "I declare that this assignment is entirely my own work based on my personal study. I further declare that I have not engaged the services of another to either assist me in, or complete this assignment”</font>\n",
        "\n",
        "### Objective\n",
        "\n",
        "The Boolean satisfiability (SAT) problem consists in determining whether a Boolean formula F is satisfiable or not. F is represented by a pair (X, C), where X is a set of Boolean variables and C is a set of clauses in Conjunctive Normal Form (CNF). Each clause is a disjunction of literals (a variable or its negation). This problem is one of the most widely studied combinatorial problems in computer science. It is the classic NP-complete problem. Over the past number of decades, a significant amount of research work has focused on solving SAT problems with both complete and incomplete solvers.\n",
        "\n",
        "Recent advances in supervised learning have provided powerful techniques for classifying problems. In this project, we see the SAT problem as a classification problem. Given a Boolean formula (represented by a vector of features), we are asked to predict if it is satisfiable or not.\n",
        "\n",
        "In this project, we represent SAT problems with a vector of 327 features with general information about the problem, e.g., number of variables, number of clauses, fraction of horn clauses in the problem, etc. There is no need to understand the features to be able to complete the assignment.\n",
        "\n",
        "The dataset is available at:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_train.csv\n",
        "\n",
        "This is original unpublished data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oav9G1WSJ1nH"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DE0kM0QsJ1En",
        "outputId": "23e9ce35-f46f-47e5-ade9-c0dc33dcaf49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     c   v  clauses_vars_ratio  vars_clauses_ratio  vcg_var_mean  \\\n",
              "0  420  10           42.000000            0.023810      0.600000   \n",
              "1  230  20           11.500000            0.086957      0.137826   \n",
              "2  240  16           15.000000            0.066667      0.300000   \n",
              "3  424  30           14.133333            0.070755      0.226415   \n",
              "4  162  19            8.526316            0.117284      0.139701   \n",
              "\n",
              "   vcg_var_coeff  vcg_var_min  vcg_var_max  vcg_var_entropy  vcg_clause_mean  \\\n",
              "0       0.000000     0.600000     0.600000         0.000000         0.600000   \n",
              "1       0.089281     0.117391     0.160870         2.180946         0.137826   \n",
              "2       0.000000     0.300000     0.300000         0.000000         0.300000   \n",
              "3       0.485913     0.056604     0.452830         2.220088         0.226415   \n",
              "4       0.121821     0.111111     0.185185         1.940843         0.139701   \n",
              "\n",
              "   ...  rwh_0_max    rwh_1_mean  rwh_1_coeff     rwh_1_min     rwh_1_max  \\\n",
              "0  ...    78750.0      0.000008          0.0  7.875000e-06      0.000008   \n",
              "1  ...  6646875.0  17433.722184          1.0  2.981244e-12  34867.444369   \n",
              "2  ...   500000.0   1525.878932          0.0  1.525879e+03   1525.878932   \n",
              "3  ...    87500.0      0.000122          1.0  6.535723e-14      0.000245   \n",
              "4  ...  5859400.0  16591.494310          1.0  6.912726e-42  33182.988621   \n",
              "\n",
              "     rwh_2_mean  rwh_2_coeff     rwh_2_min     rwh_2_max  target  \n",
              "0  2.385082e-21          0.0  2.385082e-21  2.385082e-21       1  \n",
              "1  1.727721e+04          1.0  1.358551e-53  3.455442e+04       0  \n",
              "2  1.525879e+03          0.0  1.525879e+03  1.525879e+03       1  \n",
              "3  8.218628e-07          1.0  1.499676e-61  1.643726e-06       0  \n",
              "4  1.665903e+04          1.0  0.000000e+00  3.331807e+04       1  \n",
              "\n",
              "[5 rows x 328 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad9514e3-6f57-47e2-b490-4210a5b4ce97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c</th>\n",
              "      <th>v</th>\n",
              "      <th>clauses_vars_ratio</th>\n",
              "      <th>vars_clauses_ratio</th>\n",
              "      <th>vcg_var_mean</th>\n",
              "      <th>vcg_var_coeff</th>\n",
              "      <th>vcg_var_min</th>\n",
              "      <th>vcg_var_max</th>\n",
              "      <th>vcg_var_entropy</th>\n",
              "      <th>vcg_clause_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>rwh_0_max</th>\n",
              "      <th>rwh_1_mean</th>\n",
              "      <th>rwh_1_coeff</th>\n",
              "      <th>rwh_1_min</th>\n",
              "      <th>rwh_1_max</th>\n",
              "      <th>rwh_2_mean</th>\n",
              "      <th>rwh_2_coeff</th>\n",
              "      <th>rwh_2_min</th>\n",
              "      <th>rwh_2_max</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>420</td>\n",
              "      <td>10</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.023810</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>...</td>\n",
              "      <td>78750.0</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.875000e-06</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>2.385082e-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230</td>\n",
              "      <td>20</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>0.089281</td>\n",
              "      <td>0.117391</td>\n",
              "      <td>0.160870</td>\n",
              "      <td>2.180946</td>\n",
              "      <td>0.137826</td>\n",
              "      <td>...</td>\n",
              "      <td>6646875.0</td>\n",
              "      <td>17433.722184</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.981244e-12</td>\n",
              "      <td>34867.444369</td>\n",
              "      <td>1.727721e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.358551e-53</td>\n",
              "      <td>3.455442e+04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>240</td>\n",
              "      <td>16</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>...</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1525.878932</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1.525879e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>424</td>\n",
              "      <td>30</td>\n",
              "      <td>14.133333</td>\n",
              "      <td>0.070755</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>0.485913</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>2.220088</td>\n",
              "      <td>0.226415</td>\n",
              "      <td>...</td>\n",
              "      <td>87500.0</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.535723e-14</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>8.218628e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.499676e-61</td>\n",
              "      <td>1.643726e-06</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>162</td>\n",
              "      <td>19</td>\n",
              "      <td>8.526316</td>\n",
              "      <td>0.117284</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>0.121821</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>1.940843</td>\n",
              "      <td>0.139701</td>\n",
              "      <td>...</td>\n",
              "      <td>5859400.0</td>\n",
              "      <td>16591.494310</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.912726e-42</td>\n",
              "      <td>33182.988621</td>\n",
              "      <td>1.665903e+04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.331807e+04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 328 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad9514e3-6f57-47e2-b490-4210a5b4ce97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad9514e3-6f57-47e2-b490-4210a5b4ce97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad9514e3-6f57-47e2-b490-4210a5b4ce97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/6d5738101d173b97c565f143f945dedb9c42a400/dm_assignment2/sat_dataset_train.csv?raw=true\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOqpQTS-K8EN",
        "outputId": "19bc0a17-61f1-498c-e299-6952f3eeaee2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "c                       int64\n",
              "v                       int64\n",
              "clauses_vars_ratio    float64\n",
              "vars_clauses_ratio    float64\n",
              "vcg_var_mean          float64\n",
              "                       ...   \n",
              "rwh_2_mean            float64\n",
              "rwh_2_coeff           float64\n",
              "rwh_2_min             float64\n",
              "rwh_2_max             float64\n",
              "target                  int64\n",
              "Length: 328, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#check data types\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8MCvTYTKw4Q",
        "outputId": "11742d1c-12c8-437d-c111-a30a08ee7d91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    976\n",
              "0    953\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#check count of the response variable\n",
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RsfDwCIkzbLA"
      },
      "outputs": [],
      "source": [
        "#Replace the infinity values with NAN\n",
        "df.replace([np.inf, -np.inf], np.nan,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEjqR2xLKjec",
        "outputId": "60a6c61e-9671-4de7-f7bf-65b873cc0207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['saps_EstACL_Mean', 'gsat_EstACL_Mean', 'v_nd_p_weights_entropy',\n",
              "       'v_nd_n_weights_entropy', 'c_nd_p_weights_entropy',\n",
              "       'c_nd_n_weights_entropy', 'cg_al_node_entropy', 'cg_al_weights_entropy',\n",
              "       'rg_node_entropy', 'rg_weights_entropy', 'big_node_entropy',\n",
              "       'big_weights_entropy', 'and_node_entropy', 'and_weights_entropy',\n",
              "       'band_node_entropy', 'band_weights_entropy', 'exo_node_entropy',\n",
              "       'exo_weights_entropy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check missing values in variables\n",
        "df.columns[np.isnan(df).any()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "644M1hmypYZn"
      },
      "outputs": [],
      "source": [
        "#Replace NAN values with 0\n",
        "df2 = df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuAyj_LCAlnE",
        "outputId": "60b207af-79b2-4360-eb8b-4ff0b20ab24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of data with label 1: 976\n",
            "Count of data with label 0: 953\n",
            "Minimum accuracy: 50.59616381544841\n"
          ]
        }
      ],
      "source": [
        "#Check for the minimum accuracy that the code should reach.\n",
        "df2.target\n",
        "\n",
        "label_total = df2.target.shape[0]\n",
        "\n",
        "label_1_data = sum(df2.target)\n",
        "label_0_data = label_total - label_1_data\n",
        "\n",
        "print(\"Count of data with label 1:\", label_1_data)\n",
        "print(\"Count of data with label 0:\", label_0_data)\n",
        "\n",
        "min_accuracy = max(label_1_data,label_0_data)/label_total\n",
        "print(\"Minimum accuracy:\", min_accuracy*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n23AtV8fhWxE"
      },
      "outputs": [],
      "source": [
        "#Assigning Predicting Variables to X and Target Variable Y\n",
        "features = df2.iloc[:,:-1]\n",
        "labels = df2.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check the shape of the Features and Labels*"
      ],
      "metadata": {
        "id": "JE-WOaZuDm1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into Train and test split\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Train - Test Split\n",
        "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"train_features shape:\", train_features.shape)\n",
        "print(\"train_labels shape:\", train_labels.shape)\n",
        "\n",
        "print(\"test_features:\", test_features.shape)\n",
        "print(\"test_labels:\", test_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N0XAZrQDkkP",
        "outputId": "f155b797-4609-4ef2-de41-d9b984fbd383"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_features shape: (1350, 327)\n",
            "train_labels shape: (1350,)\n",
            "test_features: (579, 327)\n",
            "test_labels: (579,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTvkBPQvITf-"
      },
      "source": [
        "# Tasks\n",
        "\n",
        "## Basic models and evaluation (5 Marks)\n",
        "\n",
        "Using Scikit-learn, train and evaluate K-NN and decision tree classifiers using 70% of the dataset from training and 30% for testing. For this part of the project, we are not interested in optimising the parameters; we just want to get an idea of the dataset. Compare the results of both classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN using Standard Scaling*"
      ],
      "metadata": {
        "id": "Xiuzix0uBkI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Train Test Split of 70-30%\n",
        "train_features_std, test_features_std, train_labels_std, test_labels_std = model_selection.train_test_split(\n",
        "                                                                                           features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "#Pipeline with Standard Scaler and KNN \n",
        "pipe_lr_std = Pipeline( [('scl_std', StandardScaler()), ('clf_knn_std',neighbors.KNeighborsClassifier(5))])\n",
        "\n",
        "#Fit the training data\n",
        "pipe_lr_std.fit(train_features_std,train_labels_std)\n",
        "\n",
        "#Accuracy on test data for KNN with standard scaler\n",
        "print('Test Accuracy knn for min_max:', pipe_lr_std.score(test_features_std, test_labels_std)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA6L3IhbANVP",
        "outputId": "dccdb6dc-606c-4113-faa8-8c8b3c9e5366"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy knn for min_max: 92.40069084628671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN using MinMax Scaling*"
      ],
      "metadata": {
        "id": "2elSVVojBrwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Train Test Split of 70-30%\n",
        "train_features_min_max, test_features_min_max, train_labels_min_max, test_labels_min_max = model_selection.train_test_split(\n",
        "                                                                                           features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "#Pipeline with min_max and KNN\n",
        "pipe_lr_min_max = Pipeline( [('scl_min_max', MinMaxScaler()), ('clf_knn_min_max',neighbors.KNeighborsClassifier(5))])\n",
        "\n",
        "#Fit the training data\n",
        "pipe_lr_min_max.fit(train_features_min_max,train_labels_min_max)\n",
        "\n",
        "#Accuracy on test data for KNN with min_max scaler\n",
        "print('Test Accuracy knn for min_max:', pipe_lr_min_max.score(test_features_min_max, test_labels_min_max)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-2ch38WBjUC",
        "outputId": "18027f1b-dd04-4a32-90a7-eb03814695bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy knn for min_max: 89.81001727115718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Decision Trees*"
      ],
      "metadata": {
        "id": "ioPpcq7DCv6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKXV6oIl2j4L",
        "outputId": "60bb8f86-768a-4f46-f8e9-a38fb09d1987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree Accuracy: 97.58203799654576\n"
          ]
        }
      ],
      "source": [
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#Decision Tree model\n",
        "dtc = tree.DecisionTreeClassifier()\n",
        "\n",
        "#fit the model\n",
        "dtc = dtc.fit(train_features, train_labels)\n",
        "\n",
        "#Accuracy of Decision treeon test data\n",
        "print('Decision tree Accuracy:',dtc.score(test_features, test_labels)*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Most of the features in this dataset are between 0 to 1, but it is not ensured that 1 is the max value or 0 is the min value in each feature; hence we perform scaling.\n",
        "\n",
        "KNN has been scaled using Min Max scaler, and Standard Scaler as the KNN is known to perform better when the features are scaled as KNN uses distance metric in the instantiation, The accuracy of the KNN model with Standard Scalar was more than the model with Min Max scaler. Standardization helps in transforming our data to have zero mean and unit variance. The main advantage of this scaler is that it's not sensitive to outliers as opposed to the Min-Max scaler, which is sensitive to outliers.\n",
        "\n",
        "We have not scaled for the decision trees because trees are not affected by scaling. After all, the splitting criterion first orders the values of each feature and then calculates the gini\\entropy of the split. Some scaling methods keep this order, so there will be no change to the accuracy score.\n",
        "\n",
        "The Decision tree stood out as the best classifier. First, however, we should perform a CV, hyperparameter tuning to rule out the possibilities of overfitting as the trees are prone to overfitting.\n",
        "\n",
        "We can see that scaling highly improved the results. We could expect it because it contains features on different scales.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2pxZBUOLscfu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zADpr0f8IcGL"
      },
      "source": [
        "## Robust evaluation (10 Marks)\n",
        "\n",
        "In this section, we are interested in more rigorous techniques by implementing more sophisticated methods, for instance:\n",
        "* Hold-out and cross-validation.\n",
        "* Hyper-parameter tuning.\n",
        "* Feature reduction.\n",
        "* Feature normalisation.\n",
        "\n",
        "Your report should provide concrete information of your reasoning; everything should be well-explained.\n",
        "\n",
        "Do not get stressed if the things you try do not improve the accuracy. The key to geting good marks is to show that you evaluated different methods and that you correctly selected the configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliLcIX6l-fg"
      },
      "source": [
        "**Feature Reduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Scale the features using Standard Scaler and assign the features to new variables to find out the variability of features*"
      ],
      "metadata": {
        "id": "BACWCZWQEbor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WeNNfynkmDz3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "features_pca = features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(features_pca)\n",
        "\n",
        "features_scaled_pca =  scaler.transform(features_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check if all the 327 explanatory variables are explaining 100 percent variability*"
      ],
      "metadata": {
        "id": "_g5Y7-bJEvRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pca_327 = PCA(n_components = 327, random_state = 42)\n",
        "\n",
        "pca_327.fit(features_scaled_pca)\n",
        "\n",
        "feature_pca_327 = pca_327.transform(features_scaled_pca)\n",
        "\n",
        "print(\"Variability explained by all 327 principal components = \", sum(pca_327.explained_variance_ratio_*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z06vCH19sbm",
        "outputId": "deb48fe8-fb3d-4b0c-a9c0-01cf82c1f1ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variability explained by all 327 principal components =  100.00000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Find the Cumulative sum of the variability explained from the model*"
      ],
      "metadata": {
        "id": "pgCxLW77E87_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot of the variability VS Number of Features*"
      ],
      "metadata": {
        "id": "jy0Mj9VvFJD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(np.cumsum(pca_327.explained_variance_ratio_*100))\n",
        "plt.axvline(linewidth=2, color='g', x=29, ymin=0, ymax=1)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('explained variance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "9s6par8R_W3q",
        "outputId": "02e4f9df-b2e5-4d4a-f8df-00ba3d1fca6e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'explained variance')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cumulative_pca = pd.DataFrame(np.cumsum(pca_327.explained_variance_ratio_*100), columns = ['Cumulative Pca Values'])\n",
        "\n",
        "#Print the component of PCA where the variablity is 95%\n",
        "print('PCA having variability greater than 95% = ' , cumulative_pca[cumulative_pca['Cumulative Pca Values'] > 95].index.values[0])\n",
        "\n",
        "print()\n",
        "\n",
        "#Print the variability Explained by first 29 Principal components\n",
        "print(\"Vaiance explained by first 29 principal components =\" , np.cumsum(pca_327.explained_variance_ratio_*100)[29])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84MV-87UBD7g",
        "outputId": "a90089f0-4c4c-4893-ed23-625ecd3c2f2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA having variability greater than 95% =  29\n",
            "\n",
            "Vaiance explained by first 29 principal components = 95.04686943322685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA Component Selection**\n",
        "\n",
        "Since we have 327 Features, PCA helps summarize the information contained in large data tables through a smaller set of summary indices that can be more easily visualized and analyzed. Overfitting is one of the main problems associated with high dimensionality data which reduces the ability of the model to generalise outside of training set.\n",
        "\n",
        "Using the plot, we could observe that the variability does not change much between the PC Components after 95%, as observed in the plot given above. We could find that the 29th component has a cumulative variability of 95%, chosen to perform CV to analyze the model performance with PCA."
      ],
      "metadata": {
        "id": "RJBM5u5R7Lf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN and Decision Trees with PCA**"
      ],
      "metadata": {
        "id": "CHS_9W29BYbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "np.random.seed(42)\n",
        "\n",
        "#Train Test Split 70-30%\n",
        "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "#Pipeline with PCA for KNN\n",
        "pipe_lr_knn_pca = Pipeline( [('scl_knn', StandardScaler()), ('pca_knn', PCA(29)),('clf_knn_pca',neighbors.KNeighborsClassifier(5))])\n",
        "\n",
        "#Pipeline with PCA for Decision Tree\n",
        "pipe_lr_dt_pca = Pipeline( [('scl_pca', StandardScaler()),('pca_dt', PCA(29)),('clf_dt_pca',tree.DecisionTreeClassifier())])\n",
        "\n",
        "#Fit KNN Model\n",
        "pipe_lr_knn_pca.fit(train_features,train_labels)\n",
        "\n",
        "#Fit Decision Treemodel\n",
        "pipe_lr_dt_pca.fit(train_features,train_labels)\n",
        "\n",
        "# Accuracies for KNN and Decision Trees using PCA\n",
        "print('Test Accuracy for KNN with PCA:', pipe_lr_knn_pca.score(test_features, test_labels)*100)\n",
        "\n",
        "print()\n",
        "\n",
        "print('Test Accuracy for Decision trees with PCA:', pipe_lr_dt_pca.score(test_features, test_labels)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhUIgoabKXC3",
        "outputId": "daa78bba-a034-41b4-893d-37e604ea20e3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for KNN with PCA: 91.36442141623489\n",
            "\n",
            "Test Accuracy for Decision trees with PCA: 87.21934369602764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "From the above result, we could see that the KNN model performed better with PCA even after the feature reduction but the decision tree accuracy reduced after the implementation of PCA; this might be due to the loss of interpretability of the data after PCA as the decision tree model works best on clear interpretation.\n"
      ],
      "metadata": {
        "id": "RUqDtXDb_fc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hold On CV**"
      ],
      "metadata": {
        "id": "6PLrBK9MNzP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train Set Accuracies with PCA and 10 Fold CV*"
      ],
      "metadata": {
        "id": "pmATUwcfQaxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "np.random.seed(42)\n",
        "\n",
        "#Pipeline with PCA for KNN\n",
        "pipe_lr_knn_cv = Pipeline( [('scl_knn', StandardScaler()), ('pca_knn', PCA(29)),('clf_knn_pca',neighbors.KNeighborsClassifier(5))])\n",
        "\n",
        "#Pipeline with PCA for Decision Tree\n",
        "pipe_lr_dt_cv_pca = Pipeline( [('pca_dt', PCA(29)),('clf_dt_pca',tree.DecisionTreeClassifier())])\n",
        "\n",
        "#Pipeline without PCA for KNN\n",
        "pipe_lr_dt_cv = Pipeline( [('clf_dt_pca',tree.DecisionTreeClassifier())])\n",
        "\n",
        "#10 fold cross validation for KNN and Decision Tree model\n",
        "knn_cv_train_result = cross_val_score(pipe_lr_knn_cv, train_features, train_labels,cv=10)\n",
        "dt_pca_cv_train_result = cross_val_score(pipe_lr_dt_cv_pca, train_features, train_labels,cv=10)\n",
        "dt_cv_train_result = cross_val_score(pipe_lr_dt_cv, train_features, train_labels,cv=10)\n",
        "\n",
        "\n",
        "print('KNN Train accuracy for 10fold CV :',knn_cv_train_result.mean()*100)\n",
        "print()\n",
        "print('Decision Tree with PCA Train accuracy for 10fold CV :',dt_pca_cv_train_result.mean()*100)\n",
        "print()\n",
        "print('Decision Tree without PCA Train accuracy for 10fold CV :',dt_cv_train_result.mean()*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hdq6hSkNgEN",
        "outputId": "481643a5-c634-4016-a10c-d6d59563569e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Train accuracy for 10fold CV : 89.7037037037037\n",
            "\n",
            "Decision Tree with PCA Train accuracy for 10fold CV : 84.66666666666667\n",
            "\n",
            "Decision Tree without PCA Train accuracy for 10fold CV : 97.85185185185185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#Fit KNN model with PCA and 10 fold CV\n",
        "pipe_lr_knn_cv.fit(train_features,train_labels)\n",
        "\n",
        "#Fit Decision Tree model with PCA and 10 fold CV\n",
        "pipe_lr_dt_cv_pca.fit(train_features,train_labels)\n",
        "\n",
        "#Fit Decision Tree model without PCA and 10 fold CV\n",
        "pipe_lr_dt_cv.fit(train_features,train_labels)\n",
        "\n",
        "\n",
        "\n",
        "# Accuracies for KNN and Decision Trees using PCA\n",
        "print('Test Accuracy for KNN with 10 Fold CV:', pipe_lr_knn_cv.score(test_features, test_labels)*100)\n",
        "\n",
        "print()\n",
        "\n",
        "print('Test Accuracy for Decision trees 10 Fold CV and PCA:', pipe_lr_dt_cv_pca.score(test_features, test_labels)*100)\n",
        "\n",
        "print()\n",
        "\n",
        "print('Test Accuracy for Decision trees 10 Fold CV and without PCA:', pipe_lr_dt_cv.score(test_features, test_labels)*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDMdGE3VQm_w",
        "outputId": "bd320528-48ce-40a9-abe0-dda56a4d3e7b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for KNN with 10 Fold CV: 91.36442141623489\n",
            "\n",
            "Test Accuracy for Decision trees 10 Fold CV and PCA: 86.52849740932642\n",
            "\n",
            "Test Accuracy for Decision trees 10 Fold CV and without PCA: 97.40932642487047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Cross-Validation is a very powerful tool. It helps us better use our data and gives us much more information about our algorithm performance. In complex machine learning models, it’s sometimes easy not to pay enough attention and use the same data in different pipeline steps. This may lead to good but not the real performance in most cases or introduce strange side effects in others. We have to pay attention that we’re confident in our models. Cross-Validation helps us when we’re dealing with non-trivial challenges.\n",
        "\n",
        "The above models, KNN, Decision tree models were trained by implementing 10-fold Cross-validation methods. We could see the KNN performed well after the cross-validation and PCA. Scaling along with PCA helps to get better performance of the model. It might be due to the outliers in the dataset that shift the PCA eigenvectors. On the other hand, those outliers don’t have such an effect when we do not use PCA.PCA almost always benefits from scaling.\n",
        "\n",
        "The decision tree  with PCA did not seem to improve, and the Decision Tree with cross-validation outperformed the other two models. It is not always true that PCA, along with CV, helps in better model performance as there might have been a component where 99% of the variance corresponds to the first PC but that PC has no relation to the underlying classes in the data. In contrast, the second PC (which only contributes 1% of the variance) is the one that can separate the classes. If we only keep the first PC, then we lose the feature that provides the ability to classify the data.\n",
        "\n",
        "To summarize, PCA worked well for KNN, but it did not perform well with Decision Trees.\n"
      ],
      "metadata": {
        "id": "AeAusCcBCe3N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RgmtaW5RWv3"
      },
      "source": [
        "**HyperParmeter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "bXAozRtIT9bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "classifierKNN = Pipeline([\n",
        "    ('scl_knn', StandardScaler()),\n",
        "    (\"pca_knn\", PCA()),\n",
        "    (\"predictor\", KNeighborsClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with the KNN classifier\n",
        "knn_param_grid = {\"pca_knn__n_components\": [29, 30, 35, 40, 45],\n",
        "                  \"predictor__n_neighbors\": [1,3,5,7,9,11,13,15],\n",
        "                  \"predictor__weights\": ['uniform','distance']\n",
        "                    }\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "knn_gs = GridSearchCV(classifierKNN, knn_param_grid, scoring=\"accuracy\",cv = 10)\n",
        "\n",
        "# Run the GridSearchCV\n",
        "knn_gs.fit(train_features,train_labels)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "knn_gs.best_params_, knn_gs.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-8jd3oUFrp",
        "outputId": "6b6f6c56-24be-4884-97fe-9c5ffbfd43a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'pca_knn__n_components': 45,\n",
              "  'predictor__n_neighbors': 11,\n",
              "  'predictor__weights': 'distance'},\n",
              " 0.9170370370370371)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "classifierKNN.set_params(**knn_gs.best_params_) \n",
        "classifierKNN.fit(train_features, train_labels)\n",
        "print('KNN Acuracy with PCA and 10 Fold CV :',accuracy_score(test_labels, classifierKNN.predict(test_features))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWo98LpKXrQr",
        "outputId": "06ca6eac-3a39-483b-893a-80eef2abf87e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Acuracy with PCA and 10 Fold CV : 92.573402417962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Trees**"
      ],
      "metadata": {
        "id": "Yhk2rCvnZYOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe3p7wzlRbxW",
        "outputId": "2748a26a-d9dd-451a-8326-64c2da5c11b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'predictor__criterion': 'entropy',\n",
              "  'predictor__max_depth': 6,\n",
              "  'predictor__min_impurity_decrease': 0.01},\n",
              " 0.9859259259259259)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "classifierDT = Pipeline([(\"predictor\", tree.DecisionTreeClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with the Decision Tree classifier\n",
        "DT_param_grid = {\"predictor__criterion\": [\"entropy\", \"gini\"],\n",
        "                 \"predictor__max_depth\": [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],\n",
        "                 \"predictor__min_impurity_decrease\": [0.01, 0.1, 0.2]\n",
        "                    }\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "dt_gs = GridSearchCV(classifierDT, DT_param_grid, scoring=\"accuracy\",cv=10)\n",
        "\n",
        "# Run the GridSearchCV\n",
        "dt_gs.fit(train_features,train_labels)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "dt_gs.best_params_, dt_gs.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "classifierDT.set_params(**dt_gs.best_params_) \n",
        "classifierDT.fit(train_features, train_labels)\n",
        "print('Decision Tree Accuracy with 10 fold CV :',accuracy_score(test_labels, classifierDT.predict(test_features))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4TKHpHrbFV9",
        "outputId": "6c084b91-aff8-4369-f8bb-93a8c28441c8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy with 10 fold CV : 97.92746113989638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The testing set is used to evaluate the model's performance that have been trained using the training set. While this is a good way to evaluate the model, it might not give a true indication of the model's performance. The data in the testing set may be skewed, and using it to evaluate the model may give a very biased result. A much better way is to divide the entire data set into k-folds (or k-parts, i.e., k-fold means dividing the dataset into 10 equal parts). Out of the k-folds, use 1 fold for testing and k-1 folds for training.\n",
        "\n",
        "In each iteration, record the metrics (such as accuracy, precision, etc.), and at the end of all the iterations, calculate the mean of these metrics. This gives the model a good mixture of the data for training and testing and gives a better benchmark for the model's performance.\n",
        "\n",
        "GridSearchCV allows us to specify different values for each hyperparameter and try out all the possible combinations when fitting the model.\n",
        "\n",
        "**Hyperparameters that are tuned in KNN are:**\n",
        "\n",
        "*   n_components: Find out the best n_components to perform PCA.\n",
        "*   n_neighbors: Find the optimal value of K.\n",
        "*   Weights: Uniform or distance.\n",
        "\n",
        "n_neighbors are chosen as an odd number. We can choose an even number. In the case of a tie vote, the decision on which class to assign will be made randomly when weights are set to uniform. By choosing an odd number, there will be no ties.\n",
        "\n",
        "Weights can be set to either uniform, where each neighbor within the boundary carries the same weight, or ‘distance’ where closer points will be more heavily weighted toward the decision.\n",
        "\n",
        "**Hyperparameters which are tuned in the Decision Tree are:**\n",
        "\n",
        "*   criterion: Gini or Entropy\n",
        "*   max_depth: The maximum depth of the tree\n",
        "*   min_impurity_decrease: A node will be split if this split induces a    decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "To summarize, We begin with one value for hyperparameters and train the model. We use different hyperparameters to train the model. We continue the method until we have exhausted the various parameter values. Every model produces an error. We pick the hyperparameter that minimizes the error. To pick the hyperparameter, we split our dataset into 3 parts, the training set, validation set, and test set. We tend to train the model for different hyperparameters. We use the error component for each model. We select the hyperparameter that minimizes the error or maximizes the score on the validation set. In ending, test our model performance using the test data.\n",
        "\n",
        "Decision Tree turned out to be the best model after hyperparameter tuning between KNN and Decision Tree."
      ],
      "metadata": {
        "id": "BJ4QtLKsIbzB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYoMg0EZIrNd"
      },
      "source": [
        "## New classifier (10 Marks)\n",
        "\n",
        "Replicate the previous task for a classifier that we did not cover in class. So different than K-NN and decision trees. Briefly describe your choice.\n",
        "Try to create the best model for the given dataset.\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset:\n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv\n",
        "\n",
        "This link currently contains a sample of the training set. The real test set will be released after the submission. I should be able to run the code cell independently, load all the libraries you need as well."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "tZg0Ogv_VSHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "pipe_lr_rf_cv = Pipeline([(\"RF\", RandomForestClassifier())])\n",
        "\n",
        "pipe_lr_rf_cv_PCA = Pipeline([('scl_knn', StandardScaler()),\n",
        "    (\"pca_knn\", PCA()),\n",
        "    (\"RF\", RandomForestClassifier())])\n",
        "\n",
        "#10 fold cross validation for RF Model\n",
        "\n",
        "RF_cv_train_result = cross_val_score(pipe_lr_rf_cv, train_features, train_labels,cv=10)\n",
        "RF_cv_train_result_PCA = cross_val_score(pipe_lr_rf_cv_PCA, train_features, train_labels,cv=10)\n",
        "\n",
        "print('RF Train accuracy for 10fold CV :',RF_cv_train_result_PCA.mean()*100)\n",
        "print('RF Train accuracy for 10fold CV and PCA:',RF_cv_train_result.mean()*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNt8eeX5Zs0X",
        "outputId": "b067cbe0-4fc5-466f-e0b3-4525ff07b1ed"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Train accuracy for 10fold CV : 92.5925925925926\n",
            "RF Train accuracy for 10fold CV and PCA: 99.25925925925925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#Fit Random Forest model with PCA and 10 fold CV\n",
        "pipe_lr_rf_cv.fit(train_features,train_labels)\n",
        "\n",
        "#Fit Random Forest model without PCA and 10 fold CV\n",
        "pipe_lr_rf_cv_PCA.fit(train_features,train_labels)\n",
        "\n",
        "# Accuracies for Random Forest using PCA and noot using PCA\n",
        "\n",
        "print('Test Accuracy for Random Forest 10 Fold CV and PCA:', pipe_lr_rf_cv_PCA.score(test_features, test_labels)*100)\n",
        "print()\n",
        "print('Test Accuracy for Random Forest with 10 Fold CV:', pipe_lr_rf_cv.score(test_features, test_labels)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5DhGqXabk0N",
        "outputId": "36ad9fdf-4794-47e9-b366-97fbe1079cfb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for Random Forest 10 Fold CV and PCA: 93.78238341968913\n",
            "\n",
            "Test Accuracy for Random Forest with 10 Fold CV: 99.3091537132988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The Random Forest model was built with PCA and without using PCA. Random forest without PCA yielded better results than the Random Forest. Hence the Random Forest without PCA was chosen to do hyperparameter tuning."
      ],
      "metadata": {
        "id": "GbO3n6P7cVGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = model_selection.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "classifierRF = Pipeline([\n",
        "    (\"RF\", RandomForestClassifier())])\n",
        "\n",
        "# Create a dictionary of hyperparameters for the pipeline with the RF classifier\n",
        "RF_param_grid = {\"RF__n_estimators\":[100,115,130,150,180],\n",
        "                 \"RF__criterion\" : ['gini','entropy'],\n",
        "                 \"RF__max_depth\":range(2,10,1),\n",
        "                 \"RF__max_features\" : ['auto','log2']\n",
        "                    }\n",
        "\n",
        "# Create the grid search object which will find the best hyperparameter values based on validation error\n",
        "rf_gs = GridSearchCV(classifierRF, RF_param_grid, scoring=\"accuracy\",cv=10)\n",
        "\n",
        "# Run the GridSearchCV\n",
        "rf_gs.fit(train_features,train_labels)\n",
        "\n",
        "# Print the best parameters and the score\n",
        "rf_gs.best_params_, rf_gs.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGoGrhMXizRz",
        "outputId": "579390d8-d34f-45d1-982a-548e89de7363"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'RF__criterion': 'entropy',\n",
              "  'RF__max_depth': 8,\n",
              "  'RF__max_features': 'auto',\n",
              "  'RF__n_estimators': 100},\n",
              " 0.9933333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "classifierRF.set_params(**rf_gs.best_params_) \n",
        "classifierRF.fit(train_features, train_labels)\n",
        "print('Random Forest test accuracy: ', accuracy_score(test_labels, classifierRF.predict(test_features))*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-bvx440f4cw",
        "outputId": "df4a0842-aca2-4ef1-caa3-7f2dede7168f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest test accuracy:  99.48186528497409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Analysis**\n",
        "\n",
        "*Accuracy*\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Decision trees are prone to overfitting, especially when a tree is particularly deep. A random forest is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit overfitting without substantially increasing error due to bias is why they are powerful models.\n",
        "Random Forests reduce variance by training on different samples of the data. A second way is by using a random subset of features.\n",
        "\n",
        "Random Forest has outperformed both KNN and Decision trees with a prediction accuracy of 99.48%. In addition, random Forest seems to give better predictions of all the models chosen.\n",
        "\n",
        "Scaling has not been performed since Random Forest is a tree-based algorithm, and tree-based algorithms do not need Scaling. The model is trained with 10-fold cross-validation with the hyperparameter tuning done by grid search CV.\n",
        "\n",
        "Hyperparameters that are tuned in the Decision Tree are:\n",
        "\n",
        "*   n_estimators: The number of trees in the forest.\n",
        "*   criterion: Criterion to measure the quality of the split.\n",
        "*   max_depth: The maximum depth of the tree.\n",
        "*   max_features: The number of features to consider when looking for the best split.\n",
        "\n",
        "On the whole Random Forest demeed to be better performing model than the other implemented model.\n",
        "\n"
      ],
      "metadata": {
        "id": "xlgyvKadWG5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "\n",
        "\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "*   https://ai.plainenglish.io/hyperparameter-tuning-of-decision-tree-classifier-using-gridsearchcv-2a6ebcaffeda\n",
        "\n",
        "*   https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6\n",
        "\n",
        "\n",
        "*   https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZN5lwmLkgkis"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q01BjiiCJTR4"
      },
      "source": [
        "# <font color=\"blue\">FOR GRADING ONLY</font>\n",
        "\n",
        "Save your best model into your github. And create a single code cell that loads it and evaluate it on the following test dataset: \n",
        "https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(classifierRF,  open(\"best_model_rf_final_4.pkl\", \"wb\" ))"
      ],
      "metadata": {
        "id": "jEmKY4Z0R4Aw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "IWx4lyuQI929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96a69ad-270a-4152-9039-61f5e61f44e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix of the best model:\n",
            " [[238   4]\n",
            " [  0 241]]\n",
            "Accurracy of the best model: 0.9917184265010351\n"
          ]
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import pickle\n",
        "\n",
        "mLink   = \"https://github.com/ManoharGanganna/DM4/blob/main/best_model_rf_final_4.pkl?raw=true\"\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "model = load(mfile)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "df_test = pd.read_csv(\"https://github.com/andvise/DataAnalyticsDatasets/blob/main/dm_assignment2/sat_dataset_test.csv?raw=true\")\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import model_selection\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import  accuracy_score, confusion_matrix\n",
        "\n",
        "xtest = df_test.iloc[:,:-1]\n",
        "ytest = df_test['target']\n",
        "\n",
        "import numpy as np\n",
        "xtest.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
        "xtest.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "print(\"Confusion matrix of the best model:\\n\",confusion_matrix(model.predict(xtest),ytest))\n",
        "print(\"Accurracy of the best model:\",accuracy_score(model.predict(xtest),ytest))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Data_Mining_Second_Assignment (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}